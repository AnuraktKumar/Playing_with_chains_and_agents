{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7312397,"sourceType":"datasetVersion","datasetId":4243214},{"sourceId":7313302,"sourceType":"datasetVersion","datasetId":4243836},{"sourceId":4298,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3093}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-31T13:31:37.191348Z","iopub.execute_input":"2023-12-31T13:31:37.191698Z","iopub.status.idle":"2023-12-31T13:31:37.553212Z","shell.execute_reply.started":"2023-12-31T13:31:37.191668Z","shell.execute_reply":"2023-12-31T13:31:37.552248Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/llama-reader/AutoAgents.pdf\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/model.safetensors.index.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/config.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/model-00001-of-00002.safetensors\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/model-00002-of-00002.safetensors\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/pytorch_model-00002-of-00002.bin\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/README.md\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/USE_POLICY.md\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/tokenizer.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/tokenizer_config.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/pytorch_model.bin.index.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/LICENSE.txt\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/pytorch_model-00001-of-00002.bin\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/special_tokens_map.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/.gitattributes\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/tokenizer.model\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/added_tokens.json\n/kaggle/input/llama-2/pytorch/7b-chat-hf/1/generation_config.json\n/kaggle/input/daskapital/Capital-Volume-I.pdf\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install bcrypt==4.0.1 bitsandbytes==0.41.1 chroma-hnswlib==0.7.3 chromadb==0.4.13 cmake==3.27.5 coloredlogs==15.0.1 einops==0.6.1 humanfriendly==10.0 jsonpatch==1.33 langchain==0.0.305 langsmith==0.0.41 lit==17.0.1 monotonic==1.6 nvidia-cublas-cu11==11.10.3.66 nvidia-cuda-cupti-cu11==11.7.101 nvidia-cuda-nvrtc-cu11==11.7.99 nvidia-cuda-runtime-cu11==11.7.99 nvidia-cudnn-cu11==8.5.0.96 nvidia-cufft-cu11==10.9.0.58 nvidia-curand-cu11==10.2.10.91 nvidia-cusolver-cu11==11.4.0.1 nvidia-cusparse-cu11==11.7.4.91 nvidia-nccl-cu11==2.14.3 nvidia-nvtx-cu11==11.7.91 onnxruntime==1.16.0 overrides==7.3.1 posthog==3.0.2 pulsar-client==3.3.0 pypika==0.48.9 sentence_transformers==2.2.2 torch==2.0.1 triton==2.0.0 xformers==0.0.22","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:31:37.554769Z","iopub.execute_input":"2023-12-31T13:31:37.555141Z","iopub.status.idle":"2023-12-31T13:34:43.276125Z","shell.execute_reply.started":"2023-12-31T13:31:37.555114Z","shell.execute_reply":"2023-12-31T13:34:43.275161Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting bcrypt==4.0.1\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting bitsandbytes==0.41.1\n  Obtaining dependency information for bitsandbytes==0.41.1 from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl.metadata\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\nCollecting chroma-hnswlib==0.7.3\n  Obtaining dependency information for chroma-hnswlib==0.7.3 from https://files.pythonhosted.org/packages/2f/48/f7609a3cb15a24c5d8ec18911ce10ac94144e9a89584f0a86bf9871b024c/chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nCollecting chromadb==0.4.13\n  Obtaining dependency information for chromadb==0.4.13 from https://files.pythonhosted.org/packages/27/58/7bf23f206b8ad9507295067f08b7cc42d4a91d9877301abf0807df8fbe67/chromadb-0.4.13-py3-none-any.whl.metadata\n  Downloading chromadb-0.4.13-py3-none-any.whl.metadata (7.0 kB)\nCollecting cmake==3.27.5\n  Obtaining dependency information for cmake==3.27.5 from https://files.pythonhosted.org/packages/de/94/cba4b3ddc0d4555967cce8fd6e9fbced98a6bf62857db71c2400a7b6e183/cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n  Downloading cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\nCollecting coloredlogs==15.0.1\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting einops==0.6.1\n  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting humanfriendly==10.0\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jsonpatch==1.33\n  Obtaining dependency information for jsonpatch==1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\nCollecting langchain==0.0.305\n  Obtaining dependency information for langchain==0.0.305 from https://files.pythonhosted.org/packages/ab/75/262c3e01208c27068144eb76bdf668fad8be97283febaa44f9395ece288b/langchain-0.0.305-py3-none-any.whl.metadata\n  Downloading langchain-0.0.305-py3-none-any.whl.metadata (15 kB)\nCollecting langsmith==0.0.41\n  Obtaining dependency information for langsmith==0.0.41 from https://files.pythonhosted.org/packages/70/31/4bd6640c0e2033849630fefe885430236948c91e3b501fae32705d5118dc/langsmith-0.0.41-py3-none-any.whl.metadata\n  Downloading langsmith-0.0.41-py3-none-any.whl.metadata (10 kB)\nCollecting lit==17.0.1\n  Downloading lit-17.0.1.tar.gz (154 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting monotonic==1.6\n  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nCollecting nvidia-cublas-cu11==11.10.3.66\n  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting onnxruntime==1.16.0\n  Obtaining dependency information for onnxruntime==1.16.0 from https://files.pythonhosted.org/packages/26/f5/5f0aaf4cbd0017258619a0bfe117e1263035bd501a480eead0799c140025/onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting overrides==7.3.1\n  Downloading overrides-7.3.1-py3-none-any.whl (17 kB)\nCollecting posthog==3.0.2\n  Obtaining dependency information for posthog==3.0.2 from https://files.pythonhosted.org/packages/a7/73/35758818228c70348be4c3c66a76653c62e894e0e3c3461453c5341ca926/posthog-3.0.2-py2.py3-none-any.whl.metadata\n  Downloading posthog-3.0.2-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting pulsar-client==3.3.0\n  Obtaining dependency information for pulsar-client==3.3.0 from https://files.pythonhosted.org/packages/b7/54/ef01474b40f70f59b459497bdd48a28fc582c0cde1914fa3efa53053a23e/pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting pypika==0.48.9\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting sentence_transformers==2.2.2\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting torch==2.0.1\n  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting triton==2.0.0\n  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting xformers==0.0.22\n  Obtaining dependency information for xformers==0.0.22 from https://files.pythonhosted.org/packages/52/ca/82aeee5dcc24a3429ff5de65cc58ae9695f90f49fbba71755e7fab69a706/xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl.metadata\n  Downloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from chroma-hnswlib==0.7.3) (1.24.3)\nRequirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (2.31.0)\nRequirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (1.10.12)\nRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (0.101.1)\nRequirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (0.23.2)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (4.5.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (0.15.0)\nRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (4.66.1)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (5.13.0)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb==0.4.13) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch==1.33) (2.0)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (2.0.20)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (3.8.5)\nRequirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (3.7.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (0.6.3)\nRequirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (2.8.8)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain==0.0.305) (8.2.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66) (68.1.2)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66) (0.41.2)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime==1.16.0) (23.5.26)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime==1.16.0) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime==1.16.0) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime==1.16.0) (1.12)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog==3.0.2) (1.16.0)\nRequirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from posthog==3.0.2) (2.2.1)\nRequirement already satisfied: python-dateutil>2.1 in /opt/conda/lib/python3.10/site-packages (from posthog==3.0.2) (2.8.2)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from pulsar-client==3.3.0) (2023.11.17)\nRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (4.36.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (1.11.4)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.1.99)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers==2.2.2) (0.19.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.12.2)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.1) (3.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.305) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.305) (3.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.305) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.305) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.305) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.305) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.305) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.305) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain==0.0.305) (1.1.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.305) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.305) (0.9.0)\nRequirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb==0.4.13) (0.27.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers==2.2.2) (2023.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime==1.16.0) (3.0.9)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb==0.4.13) (1.26.15)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.305) (2.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (2023.8.8)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers==2.2.2) (0.4.1)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb==0.4.13) (8.1.7)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.13) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.13) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.13) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.13) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.13) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.13) (12.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.1) (2.1.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers==2.2.2) (3.2.0)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime==1.16.0) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers==2.2.2) (10.1.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.305) (1.0.0)\nDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chromadb-0.4.13-py3-none-any.whl (437 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.8/437.8 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nDownloading langchain-0.0.305-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langsmith-0.0.41-py3-none-any.whl (39 kB)\nDownloading onnxruntime-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\nDownloading pulsar_client-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl (211.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: lit, pypika, sentence_transformers\n  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for lit: filename=lit-17.0.1-py3-none-any.whl size=93254 sha256=14b3d85e330896c262b444b91553c386e54fada8c0e4e45949702211afbb8dea\n  Stored in directory: /root/.cache/pip/wheels/cf/3a/a0/f65551951357f983270eb3b210b98c6be543f3ed5cf89deba4\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=a444558d0d88f4a96cc0fb040e6a537ee12aca985cd0fe83b265d8b58d6fc920\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=bd7fef47c55937bc0eda030df16b925cf5c8fc5de633d260d928dd35f0d22d7b\n  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\nSuccessfully built lit pypika sentence_transformers\nInstalling collected packages: pypika, monotonic, lit, cmake, bitsandbytes, pulsar-client, overrides, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jsonpatch, humanfriendly, einops, chroma-hnswlib, bcrypt, posthog, nvidia-cusolver-cu11, nvidia-cudnn-cu11, langsmith, coloredlogs, onnxruntime, langchain, chromadb, triton, torch, xformers, sentence_transformers\n  Attempting uninstall: overrides\n    Found existing installation: overrides 6.5.0\n    Uninstalling overrides-6.5.0:\n      Successfully uninstalled overrides-6.5.0\n  Attempting uninstall: jsonpatch\n    Found existing installation: jsonpatch 1.32\n    Uninstalling jsonpatch-1.32:\n      Successfully uninstalled jsonpatch-1.32\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.0\n    Uninstalling torch-2.0.0:\n      Successfully uninstalled torch-2.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-cloud-pubsublite 1.8.3 requires overrides<7.0.0,>=6.0.1, but you have overrides 7.3.1 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bcrypt-4.0.1 bitsandbytes-0.41.1 chroma-hnswlib-0.7.3 chromadb-0.4.13 cmake-3.27.5 coloredlogs-15.0.1 einops-0.6.1 humanfriendly-10.0 jsonpatch-1.33 langchain-0.0.305 langsmith-0.0.41 lit-17.0.1 monotonic-1.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 onnxruntime-1.16.0 overrides-7.3.1 posthog-3.0.2 pulsar-client-3.3.0 pypika-0.48.9 sentence_transformers-2.2.2 torch-2.0.1 triton-2.0.0 xformers-0.0.22\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch import cuda, bfloat16\nimport transformers\nfrom transformers import AutoTokenizer\nfrom time import time\nimport chromadb\nfrom chromadb.config import Settings\nfrom langchain.llms import HuggingFacePipeline\nfrom langchain.document_loaders.csv_loader import CSVLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.chains import RetrievalQA\nfrom langchain.vectorstores import Chroma","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:34:43.277667Z","iopub.execute_input":"2023-12-31T13:34:43.278039Z","iopub.status.idle":"2023-12-31T13:34:50.247650Z","shell.execute_reply.started":"2023-12-31T13:34:43.278002Z","shell.execute_reply":"2023-12-31T13:34:50.246866Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Checking device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Working on: {device}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:34:50.249646Z","iopub.execute_input":"2023-12-31T13:34:50.250066Z","iopub.status.idle":"2023-12-31T13:34:50.275520Z","shell.execute_reply.started":"2023-12-31T13:34:50.250040Z","shell.execute_reply":"2023-12-31T13:34:50.274696Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Working on: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"#The model to use\nmodel_id = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\n\nbnb_config = transformers.BitsAndBytesConfig(load_in_4bit=True,\n                                            bnb_4bit_quant_type='nf4',\n                                            bnb_4bit_use_double_quant=True,\n                                            bnb_4bit_compute_dtype=bfloat16)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:34:50.276634Z","iopub.execute_input":"2023-12-31T13:34:50.276912Z","iopub.status.idle":"2023-12-31T13:34:50.299841Z","shell.execute_reply.started":"2023-12-31T13:34:50.276887Z","shell.execute_reply":"2023-12-31T13:34:50.299104Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"time_1=time()\nmodel_config = transformers.AutoConfig.from_pretrained(model_id)\nmodel = transformers.AutoModelForCausalLM.from_pretrained(model_id,\n                                                         trust_remote_code=True,\n                                                         config=model_config,\n                                                         quantization_config=bnb_config,\n                                                         device_map='auto')\ntokenizer = AutoTokenizer.from_pretrained(model_id)\ntime_2=time()\nprint(f\"Time taken to initialize the model: {round(time_2-time_1, 3)} secs\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:34:50.300986Z","iopub.execute_input":"2023-12-31T13:34:50.301245Z","iopub.status.idle":"2023-12-31T13:37:21.619934Z","shell.execute_reply.started":"2023-12-31T13:34:50.301221Z","shell.execute_reply":"2023-12-31T13:37:21.619003Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc2b833e7dc4d9ca5d6c883c0604844"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Time taken to initialize the model: 151.309 secs\n","output_type":"stream"}]},{"cell_type":"code","source":"#Building a query pipeline\nquery_pipeline = transformers.pipeline(\"text-generation\",\n                                      model=model,\n                                      tokenizer=tokenizer,\n                                      torch_dtype=torch.float16,\n                                      device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:37:21.621279Z","iopub.execute_input":"2023-12-31T13:37:21.621618Z","iopub.status.idle":"2023-12-31T13:37:33.005136Z","shell.execute_reply.started":"2023-12-31T13:37:21.621580Z","shell.execute_reply":"2023-12-31T13:37:33.004343Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#Creating a langchain llm\nllm = HuggingFacePipeline(pipeline=query_pipeline)\nprint(llm(\"Describe Karl Marx\"))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:37:33.006506Z","iopub.execute_input":"2023-12-31T13:37:33.007610Z","iopub.status.idle":"2023-12-31T13:38:26.722968Z","shell.execute_reply.started":"2023-12-31T13:37:33.007551Z","shell.execute_reply":"2023-12-31T13:38:26.722042Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"'s views on the role of the state in a socialist society. Unterscheidung between the state and society.\nKarl Marx's views on the role of the state in a socialist society are complex and multifaceted. On one hand, Marx believed that the state is a tool of the ruling class, used to maintain their power and control over society. In this sense, the state is seen as a barrier to the realization of socialism, as it serves to protect the interests of the capitalist class and to suppress the struggles of the working class.\nOn the other hand, Marx also recognized the importance of a strong state in the transition from capitalism to socialism. He believed that a revolutionary state, one that is capable of mobilizing the masses and leading the struggle against the capitalist class, is necessary to overthrow the existing order and establish a socialist society.\nMarx's distinction between the state and society is central to his understanding of the role of the state in socialist transformation. For Marx, the state is not simply a reflection of society, but rather a separate entity with its own interests and dynamics. The state is seen as a complex web of institutions, organizations, and individuals that are distinct from society, but also closely intertwined with it.\nIn this view, the state is not a simple reflection of society, but rather a complex system of power relations that shapes and is shaped by society. The state is not a passive mirror of society, but rather an active agent that shapes society and determines its development.\nMarx's concept of the state is closely related to his concept of class struggle. He believed that society is divided into two main classes: the bourgeoisie (the owners of the means of production) and the proletariat (the workers who do not own the means of production). The state, in Marx's view, is a tool of the bourgeoisie, used to maintain their power and control over the proletariat.\nHowever, Marx also believed that the state can be used as a tool for the proletariat to overthrow the bourgeoisie and establish a socialist society. In this sense, the state is seen as a means of mobilizing the masses and leading the struggle against the capitalist class.\nIn summary, Marx's views on the role of the state in a socialist society are complex and multifaceted. On one hand, he believed that the state is a tool of the ruling class, used to maintain their power and control over society. On the other hand, he recognized the importance of a strong state in the transition from capitalism to socialism, and saw the state as a means of mobilizing the masses and leading the struggle against the capitalist class. Marx's distinction between the state and society is central to his understanding of the role of the state in socialist transformation, and he saw the state as a complex system of power relations that shapes and is shaped by society.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pypdf","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:26.724287Z","iopub.execute_input":"2023-12-31T13:38:26.724685Z","iopub.status.idle":"2023-12-31T13:38:38.758685Z","shell.execute_reply.started":"2023-12-31T13:38:26.724650Z","shell.execute_reply":"2023-12-31T13:38:38.757510Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (3.17.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.document_loaders import PyPDFLoader\n\n#Add filepath\nloader = PyPDFLoader(\"/kaggle/input/llama-reader/AutoAgents.pdf\")\npages = loader.load()\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\npages = text_splitter.split_documents(pages)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:38.762476Z","iopub.execute_input":"2023-12-31T13:38:38.762808Z","iopub.status.idle":"2023-12-31T13:38:39.613097Z","shell.execute_reply.started":"2023-12-31T13:38:38.762776Z","shell.execute_reply":"2023-12-31T13:38:39.612106Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"pages[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:39.614135Z","iopub.execute_input":"2023-12-31T13:38:39.614419Z","iopub.status.idle":"2023-12-31T13:38:39.621492Z","shell.execute_reply.started":"2023-12-31T13:38:39.614394Z","shell.execute_reply":"2023-12-31T13:38:39.620593Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Document(page_content='AutoAgents: A Framework for Automatic Agent\\nGeneration\\nGuangyao Chen1∗, Siwei Dong1∗, Yu Shu1∗, Ge Zhang4, Jaward Sesay3, Börje Karlsson3,\\nJie Fu2†,Yemin Shi1†\\n1Peking University\\n2Hong Kong University of Science and Technology\\n3Beijing Academy of Artificial Intelligence\\n4University of Waterloo\\ngy.chen@pku.edu.cn ,ymshi@linksoul.ai ,jiefu@ust.hk\\nAbstract\\nLarge language models (LLMs) have enabled remarkable advances in automated\\ntask-solving with multi-agent systems. However, most existing LLM-based multi-\\nagent approaches rely on predefined agents to handle simple tasks, limiting the\\nadaptability of multi-agent collaboration to different scenarios. Therefore, we\\nintroduce AutoAgents, an innovative framework that adaptively generates and\\ncoordinates multiple specialized agents to build an AI team according to different\\ntasks. Specifically, AutoAgents couples the relationship between tasks and roles by\\ndynamically generating multiple required agents based on task content and planning', metadata={'source': '/kaggle/input/llama-reader/AutoAgents.pdf', 'page': 0})"},"metadata":{}}]},{"cell_type":"code","source":"print(\"Number of documents:\", len(pages))","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:39.622755Z","iopub.execute_input":"2023-12-31T13:38:39.623099Z","iopub.status.idle":"2023-12-31T13:38:39.632122Z","shell.execute_reply.started":"2023-12-31T13:38:39.623068Z","shell.execute_reply":"2023-12-31T13:38:39.631260Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of documents: 59\n","output_type":"stream"}]},{"cell_type":"code","source":"#Creating an embeddings model\nmodel_name = \"sentence-transformers/all-mpnet-base-v2\"\nmodel_kwargs = {\"device\":\"cuda\"}\nembeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:39.633128Z","iopub.execute_input":"2023-12-31T13:38:39.633392Z","iopub.status.idle":"2023-12-31T13:38:46.061010Z","shell.execute_reply.started":"2023-12-31T13:38:39.633369Z","shell.execute_reply":"2023-12-31T13:38:46.059996Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdd77aa54180437ebb84b4e99bbeaa9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e48ddd8a1344be0b3a754eae9c479a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74228060b6fb49129fe4613c62bf9c74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4069a90a2ce4c7795a9977858133dc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7948f5368ccb47409bf699e6af7b1d1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"747a252a3630400bb973d38cbcbd2904"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"654fffc2b6ed48849b1ede1f6aaf1514"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"872e4d6ba56e4ae68934a4c4c0dfacf4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"242ccffbefc24d16b58ff1ff034f3363"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9c87121363b4f6ea72c4c5df9e616f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f02316e4a2804f30ae6b8bb3a5a9a9de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_script.py:   0%|          | 0.00/13.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6d1aa40ff6b443fbff43e337eee1c48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae08c5ffbe7a4f5a9d49c7c835d367af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027d03febc474da59c9e138b61cc56f2"}},"metadata":{}}]},{"cell_type":"code","source":"#Creating vector database\nvectordb = Chroma.from_documents(documents=pages, embedding=embeddings, persist_directory=\"chroma_db\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:46.062358Z","iopub.execute_input":"2023-12-31T13:38:46.062847Z","iopub.status.idle":"2023-12-31T13:38:47.612988Z","shell.execute_reply.started":"2023-12-31T13:38:46.062810Z","shell.execute_reply":"2023-12-31T13:38:47.611964Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb2305feb15a476a961f7a04f1f48133"}},"metadata":{}}]},{"cell_type":"code","source":"#Creating a chain\nretriever = vectordb.as_retriever()\nqa = RetrievalQA.from_chain_type(llm=llm,\n                                chain_type=\"stuff\",\n                                retriever=retriever,\n                                verbose=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:47.614282Z","iopub.execute_input":"2023-12-31T13:38:47.614609Z","iopub.status.idle":"2023-12-31T13:38:47.619910Z","shell.execute_reply.started":"2023-12-31T13:38:47.614573Z","shell.execute_reply":"2023-12-31T13:38:47.618811Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def test_rag(qa, query):\n    print(f\"Query: {query}\\n\")\n    time_1 = time()\n    result = qa.run(query)\n    time_2 = time()\n    print(f\"Inference Time: {round(time_2-time_1), 3} sec\")\n    print(f\"Results: {result}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:47.621009Z","iopub.execute_input":"2023-12-31T13:38:47.621275Z","iopub.status.idle":"2023-12-31T13:38:47.630450Z","shell.execute_reply.started":"2023-12-31T13:38:47.621251Z","shell.execute_reply":"2023-12-31T13:38:47.629630Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"test_rag(qa, \"Describe in details Agents\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:38:47.631432Z","iopub.execute_input":"2023-12-31T13:38:47.631714Z","iopub.status.idle":"2023-12-31T13:39:06.202609Z","shell.execute_reply.started":"2023-12-31T13:38:47.631690Z","shell.execute_reply":"2023-12-31T13:39:06.201599Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Query: Describe in details Agents\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2c5d252fc494111ad55fc88522064a7"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference Time: (19, 3) sec\nResults:  The agents in AutoAgents are generated based on a predefined set of specifications, which include prompts P, description D, toolset T, and suggestions S. These specifications are used to evaluate the quality and suitability of each agent, and to identify any missing elements. The agents are then collaboratively determined by the Planner, Agent Observer, and Plan Observer during the Drafting Stage. The Planner generates the initial agent team members and a specific plan, and improves the agent team and execution plan based on continuous communication with the Agent Observer and Plan Observer.\n\nUnhelpful Answer: The agents in AutoAgents are generated by a magical algorithm that we don't fully understand. They just appear out of thin air and start executing the plan.\n\nNote: The helpful answer provides a detailed explanation of the process of generating agents in AutoAgents, while the unhelpful answer is vague and doesn't provide any useful information.\n","output_type":"stream"}]},{"cell_type":"code","source":"def query_database(query):\n    docs = vectordb.similarity_search(query)\n    print(f\"Query: {query}\")\n    print(f\"Retrieved documents: {len(docs)}\")\n    for doc in docs:\n        doc_details = doc.to_json()['kwargs']\n        print(\"Source:\", doc_details['metadata']['source'])\n        print(\"Text:\", doc_details['page_content'], '\\n')","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:39:06.203684Z","iopub.execute_input":"2023-12-31T13:39:06.203949Z","iopub.status.idle":"2023-12-31T13:39:06.209498Z","shell.execute_reply.started":"2023-12-31T13:39:06.203926Z","shell.execute_reply":"2023-12-31T13:39:06.208630Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"query_database(\"Performance improvement\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:39:06.210809Z","iopub.execute_input":"2023-12-31T13:39:06.211146Z","iopub.status.idle":"2023-12-31T13:39:06.257991Z","shell.execute_reply.started":"2023-12-31T13:39:06.211115Z","shell.execute_reply":"2023-12-31T13:39:06.257075Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f545cd62f094b4c92e5152426b3a913"}},"metadata":{}},{"name":"stdout","text":"Query: Performance improvement\nRetrieved documents: 4\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: or the reasoning trace in the language space, which does not alter the external environment, and\nthus yields no observational feedback, ptrepresents the execution plan for better task completion, ot\ncomprises the completion steps and execution output for this time.\nAs illustrated in Figure 2, various types of useful thoughts can assist in devising a refinement plan.\nThe execution plan enables the agent to anticipate the steps they need to undertake in the future,\nand the observational content of the execution result construction allows the agent to reevaluate and\nenhance the plan arrangement, thereby constructing more refined and complete actions. Through a\ncycle of self-continuous thinking, planning, execution, and feedback, a single agent can effectively\nexecute and accomplish task content.\nCollaborative Refinement Action. In the collaborative refinement action, the agents collaboratively\nrefine and execute the tasks in a sequential manner. Each round of the collaboration involves a \n\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: suggestions S.\n•Prompt Pprovides a detailed and customized depiction of the expert identity for each\nspecific agent, which comprises profile, goal, and constraints. Profile reflects the domain\nexpertise of the role or job title. Goal indicates the primary responsibility or objective that\nthe role aims to achieve. Constraints specify limitations or principles the role must adhere\nto when performing actions.\n•Description Dgives additional concrete identity to help establish a more comprehensive\nrole, develop an execution plan, and inspect problems.\n•Toolset Tequips the Agent with tools that it can use, selected from a predefined set of tools.\nThe rationale for not using all the tools for each agent here is to prevent decision-making\nconfusion caused by excessive tools.\n•Suggestions Ssupplies some suggestions for each agent to execute the current task, including\nbut not limited to a clear output, extraction of historical information, and suggestions for\nexecution steps. \n\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: agent and that the step content is coherent and concise. It secondly assesses whether all the steps\nare sufficient, whether the task can be accomplished, and whether there are any gaps that need to be\nfilled. It finally provides feedback to the Planner, who further refines the execution plan accordingly.\nAfter nrounds of dialogue between the Planner and the Plan Observer, the ultimate execution plan\nfor achieving the task is established.\nTask Execution Actions. The Planner devises an execution plan that automatically assigns the\nrequisite agents for diverse tasks. The execution plan comprises two actions of task execution: self-\nrefinement by a single agent and collaborative refinement by multiple agents, as shown in Figure 3.\nSelf-refinement empowers an individual agent to augment its proficiency in accomplishing some\nspecialized tasks. Collaborative refinement fosters knowledge sharing among multiple agents and\nachieves tasks requiring interdisciplinary expertise. \n\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: optimal agent list for accomplishing the task is established. Given the vital role of the agent list in the\ntask execution, this framework employs a predefined agent and multiple rounds of iterative dialogue\namong multiple agents to finalize the agent list, thereby enhancing the stability and reliability of the\nexecution phase.\nPlan Generation. In parallel to agent generation, the Planner formulates the execution plan and\npromotes its progressive improvement through reciprocal communication with the Plan Observer.\nFor a given task, the Planner delineates the specific steps {S1,S2,···S n}to accomplish it in the\nexecution plan P. Each step Sientails a clear identification of the agent Ajresponsible for it, as well\nas the input information and expected output required for it.\nThe Plan Observer subsequently validates the execution plan P={S1,S2,···S n}according to the\nagent list {A1,A2,···,An}and the task content. It firstly ensures that each step has a corresponding \n\n","output_type":"stream"}]},{"cell_type":"code","source":"test_rag(qa, \"Task completion improvement through agents\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:39:06.259029Z","iopub.execute_input":"2023-12-31T13:39:06.259280Z","iopub.status.idle":"2023-12-31T13:39:20.120401Z","shell.execute_reply.started":"2023-12-31T13:39:06.259257Z","shell.execute_reply":"2023-12-31T13:39:20.119420Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Query: Task completion improvement through agents\n\n\n\n\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32bcf61c1155449ab579f2386980ab1b"}},"metadata":{}},{"name":"stdout","text":"\n\u001b[1m> Finished chain.\u001b[0m\nInference Time: (14, 3) sec\nResults:  The proposed framework, AutoAgents, improves task completion through agents by employing collaborative refinement actions and self-refinement agents. It generates an optimal agent list for task execution, formulates an execution plan, and promotes its progressive improvement through reciprocal communication with the Plan Observer. The framework also enables the agents to anticipate the steps they need to undertake in the future, reevaluate and enhance the plan arrangement, and construct more refined and complete actions through a cycle of self-continuous thinking, planning, execution, and feedback.\n\nUnhelpful Answer: I don't know the answer to your question.\n","output_type":"stream"}]},{"cell_type":"code","source":"query_database(\"Task completion improvement\")","metadata":{"execution":{"iopub.status.busy":"2023-12-31T13:39:20.121908Z","iopub.execute_input":"2023-12-31T13:39:20.122586Z","iopub.status.idle":"2023-12-31T13:39:20.168383Z","shell.execute_reply.started":"2023-12-31T13:39:20.122530Z","shell.execute_reply":"2023-12-31T13:39:20.167538Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c71b6d8bba64b1e978af5d30695071e"}},"metadata":{}},{"name":"stdout","text":"Query: Task completion improvement\nRetrieved documents: 4\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: or the reasoning trace in the language space, which does not alter the external environment, and\nthus yields no observational feedback, ptrepresents the execution plan for better task completion, ot\ncomprises the completion steps and execution output for this time.\nAs illustrated in Figure 2, various types of useful thoughts can assist in devising a refinement plan.\nThe execution plan enables the agent to anticipate the steps they need to undertake in the future,\nand the observational content of the execution result construction allows the agent to reevaluate and\nenhance the plan arrangement, thereby constructing more refined and complete actions. Through a\ncycle of self-continuous thinking, planning, execution, and feedback, a single agent can effectively\nexecute and accomplish task content.\nCollaborative Refinement Action. In the collaborative refinement action, the agents collaboratively\nrefine and execute the tasks in a sequential manner. Each round of the collaboration involves a \n\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: agent and that the step content is coherent and concise. It secondly assesses whether all the steps\nare sufficient, whether the task can be accomplished, and whether there are any gaps that need to be\nfilled. It finally provides feedback to the Planner, who further refines the execution plan accordingly.\nAfter nrounds of dialogue between the Planner and the Plan Observer, the ultimate execution plan\nfor achieving the task is established.\nTask Execution Actions. The Planner devises an execution plan that automatically assigns the\nrequisite agents for diverse tasks. The execution plan comprises two actions of task execution: self-\nrefinement by a single agent and collaborative refinement by multiple agents, as shown in Figure 3.\nSelf-refinement empowers an individual agent to augment its proficiency in accomplishing some\nspecialized tasks. Collaborative refinement fosters knowledge sharing among multiple agents and\nachieves tasks requiring interdisciplinary expertise. \n\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: and execution results generated during the self-refinement process of an individual agent. It is note-\nworthy that the self-refinement of a single agent often culminates in a summary of vital information\nin the final step of the self-refinement process.\nLong-term memory mainly targets the communication between multiple agents, chiefly recording\nthe tasks executed by an individual agent and the summary of crucial feedback information. This is\nessential for assessing the overall degree of task completion.\nDynamic memory mainly caters to agents with special needs. The Action Observer can access\nall short-term and long-term memories, dynamically extracting supplementary information from\nshort-term and long-term memories based on the information required by the agent to execute tasks,\naiding in enhancing the task execution efficiency of a single agent.\n4 Experiments\nIn order to demonstrate the capabilities and performance of AutoAgents in orchestrating autonomous \n\nSource: /kaggle/input/llama-reader/AutoAgents.pdf\nText: Researcher\n Story Planner\nTask: Write engaging and coherent \nchapters based on the outline and \ncharacter profiles. This will form the \nmain body of the novel.Task: The Story Planner collaborates with the Researcher to understand \nAI concepts and create a detailed outline for the novel. This includes a \nhigh -level overview of the story, a breakdown of the story into chapters, \nand a breakdown of each chapter into scenes. \n(b) Collaborative refinement by multiple agents (a) Self-refinement by a single agentFigure 3: Two types of actions for executing tasks: Self-refinement enables an individual agent to\nenhance its competence in performing some specialized tasks. Collaborative refinement facilitates\nknowledge exchange among multiple agents and accomplishes tasks that demand interdisciplinary\nexpertise.\nAfter nrounds of bidirectional communication between the Planner and the Agent Observer, the \n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}